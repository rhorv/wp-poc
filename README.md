# WP processing POC

## Disclaimer

This project is meant to be used as a POC for structure and design.  

## What this project is

This small project is meant to be an implementation of a minimalistic 
processing system with a few small components. These small components are meant  
to be their own separate services, but for simplicity they are just implemented as  
separate packages 

This project contains the following packages
- "events": contains all the interfaces and adapters for event processing
- "poc": only contains a single class entrypoint to launch the consumer
- "clearing": POC implementation of a clearing system
- "pricing": POC implementation of a pricing system

## Pre-requisites

First and foremost you will need GNU make.  
If you have that you can run ``make check-deps`` for a rudementary dependency check.   
This will check for things you need (not for specific versions though just yet)

You will definitely need the following things:
- java 8 (tested with openJDK version 1.8.0_282)
- docker (tested with 12.03.13)
- docker-compose (tested with 1.25.0)
- maven (tested with 3.6.3)

## How to set the project up

This looks long and complicated, but don't worry, it is really just a few commands to run and a few values to change (if you want to), the rest is just explanation.

**Initialize the project:**  
1. Check that you have everything with ``make check-deps``
2. Go into the ``docker`` directory inside the project, you will find 4 other directories (kafka, rabbitmq, elk, and confluent-schema-registry) with ``.env.example`` files in them.  
   These files are provided for your convenience. Make a copy of each of them in the same directory, named ``.env``. The only thing you should change in the copied ``.env`` files at this point is the HOME directory for each service. These define where the persistent data generated by these services is stored (otherwise all data would be lost when the container shuts down).  
   I'd recommend changing them to somewhere outside the project directory, for example "/srv/docker-data/whatever-servicename" (Please note, that you cannot use "~" or "$HOME" in the path, these should be absolute paths, and you should have a unique one for each service)
3. Run ``make init``. This will create the common network the docker containers use, and create the persistent data mounts for the docker containers

**Set up Kafka:**   
4. Run ``make kafka-start``   
   This will start up the kafka containers. You can visit "http://localhost:9000" to view KafDrop (no user/pass required) to verify that it's up and running. You should also be able to see 3 containers running for Kafka in ``docker ps`` (1 for kafka, 1 for zookeeper, and 1 for kafdrop)
5. Run ``make kafka-setup``   
   This will initialize the topics for kafka
   
**Set up ELK (for monitoring):**    
6. Run ``make elk-start``   
   This start the elk containers. You can visit "http://localhost:5601" to open kibana (you might need to give it a minute, this one is quite slow to start up). You should also be able to see 3 containers running for ELK (1 for elasticsearch, 1 for logstash, and 1 for kibana)

You should be good to go at this point.

## Extra steps for setting up kibana

There is a bonus step for setting up the index for kibana, this can only be done after at least 1 message got published
Once that's done (you can verify the message in KafDrop or rabbitMQ management), you should:
1. Visit "http://localhost:5601"
2. Click the big box titled "Kibana" (on the right side)
3. Click "Add your data"
4. Click "Create Index Pattern"
5. You should see a source in the list titles "message-<date>"
6. Type in "messages-*" into the "index pattern name" box and click "Next"
7. Select either "@timestamp" or "occurred_at" from the dropdown menu and click Done 

You should be able to see messages coming through now if you select "Discover" from the hamburger menu on the top left side (Under Analytics) 

## How to build the project

This one is easy, just run ``make`` (or ``make build``)

## How to run the tests

Also easy, just run ``make test``

## How to run the project

There are 2 ways of running the code, by hand/from your IDE, or as a docker container

### Running the code by hand

After building the project, you should be able to run the main application by running ``java -jar target/gs-maven-0.1.0.jar``
This will start the currently configured consumer

### Running the code from your IDE

1. Set the project up in your favorite IDE
2. Make sure you define these in your ``/etc/hosts``:  
``127.0.0.1 kafka``  
3. Click run in your IDE

Running "MyApplication" will run the consumer and kick the example off with a command   

### Running the code as a docker container

In order to run the project in a docker container:
1. Build the container by running ``make container``
2. Run ``docker run --network=poc-wp wp-poc`` (or simply run ``docker-compose up`` from the project root directory)

